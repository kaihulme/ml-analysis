import numpy as np
import pandas as pd
import pymc3 as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
# from bayesian_linear_regressor import BayesianLinearRegression


housing_data = fetch_california_housing(as_frame=True)

df = housing_data['frame']
print(df.columns)


print(df.dtypes)


latitude = df['Latitude']
longitude = df['Longitude']

fig, ax = plt.subplots(figsize=(12, 8))
plt.title("Geographical Plot of California Housing Data")
plt.xlabel("Latitude")
plt.ylabel("Longitude")
plt.scatter(latitude, longitude, s=10, alpha=0.25)
plt.show()


house_val = df['MedHouseVal']
population = df['Population']

fig, ax = plt.subplots(figsize=(12, 8))
plt.title("California Housing Value and Geographical Location")
plt.xlabel("Latitude")
plt.ylabel("Longitude")
plt.scatter(latitude, longitude, s=population/100, alpha=0.5, c=house_val, cmap='coolwarm')
plt.colorbar().set_label("Median House Value (scale of 0-5)")
plt.show()


df.describe()


non_geo = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',
           'Population', 'AveOccup', 'MedHouseVal']

corr = df[non_geo].corr()
print(corr)


fig, ax = plt.subplots(figsize=(12, 8))
ax.set_title("Correlation of Non-Geographical Features", fontsize=16)
mat = ax.matshow(corr)
ax.set_xticks(range(len(non_geo)))
ax.set_yticks(range(len(non_geo)))
ax.set_xticklabels(non_geo, rotation=-90, fontsize=12)
ax.set_yticklabels(non_geo, fontsize=12)
plt.colorbar(mat, ax=ax)
plt.show()


df_nohigh = df.astype(float)
df_nohigh = df_nohigh.drop(df_nohigh[(df_nohigh['MedInc'] > 10) |
                                     (df_nohigh['HouseAge'] > 50) |
                                     (df_nohigh['AveRooms'] > 10) |
                                     (df_nohigh['AveBedrms'] > 2) |
                                     (df_nohigh['Population'] > 6000) |
                                     (df_nohigh['AveOccup'] > 8) |
                                     (df_nohigh['MedHouseVal'] > 4.7)].index)


df_nohigh[non_geo].hist(bins=50, figsize=(12, 8))


df_nohighnormal = df_nohigh.copy()
df_nohighnormal["MedInc"] = np.log1p(df_nohighnormal['MedInc'])
df_nohighnormal["AveRooms"] = np.log1p(df_nohighnormal['AveRooms'])
df_nohighnormal["AveBedrms"] = np.log1p(df_nohighnormal['AveBedrms'])
df_nohighnormal["Population"] = np.log1p(df_nohighnormal['Population'])
df_nohighnormal["AveOccup"] = np.log1p(df_nohighnormal['AveOccup'])
df_nohighnormal["MedHouseVal"] = np.log1p(df_nohighnormal['MedHouseVal'])

df_nohighnormal[non_geo].hist(bins=50, figsize=(12, 8))


df_normal = df.copy()
df_normal["MedInc"] = np.log1p(df_normal['MedInc'])
df_normal["AveRooms"] = np.log1p(df_normal['AveRooms'])
df_normal["AveBedrms"] = np.log1p(df_normal['AveBedrms'])
df_normal["Population"] = np.log1p(df_normal['Population'])
df_normal["AveOccup"] = np.log1p(df_normal['AveOccup'])
df_normal["MedHouseVal"] = np.log1p(df_normal['MedHouseVal'])


df_normal.isnull().sum()


df_cut = df_normal.copy()
df_cut[non_geo].hist(bins=50, figsize=(16, 16))


# df_nohigh = df[non_geo].astype(float)
df_cut = df_cut.drop(df_cut[(df_cut['HouseAge'] > 50) |
                            (df_cut['MedHouseVal'] > 1.75)].index)

df_cut.hist(bins=50, figsize=(12, 8))


print(df_cut.columns)


extra_df = df_cut.copy()

extra_df['AveBedrmsPerRoom'] = extra_df['AveBedrms'] / extra_df['AveRooms']
extra_df['AveBedrmsPerOccup'] = extra_df['AveBedrms'] / extra_df['AveOccup']
extra_df['AveAddRooms'] = extra_df['AveRooms'] - extra_df['AveBedrms']
extra_df['EstHouses'] = extra_df['Population'] / extra_df['AveOccup']

new_features = ['MedHouseVal', 'AveBedrmsPerRoom', 'AveBedrmsPerOccup',
                'AveAddRooms', 'EstHouses']

new_features_corr = extra_df.corr()
new_features_corr['MedHouseVal'].abs().sort_values(ascending=False)

# fig, ax = plt.subplots(figsize=(12, 8))
# ax.set_title("Correlation of Non-Geographical Features", fontsize=16)
# mat = ax.matshow(new_features_corr)
# ax.set_xticks(range(len(new_features)))
# ax.set_yticks(range(len(new_features)))
# ax.set_xticklabels(new_features, rotation=-90, fontsize=12)
# ax.set_yticklabels(new_features, fontsize=12)
# plt.colorbar(mat, ax=ax)
# plt.show()


# LA location as north-westerly peak
la_lat, la_lon = 34, -118
# SF location as south-easterly peak
sf_lat, sf_lon = 38, -122

extra_df['DistToLA'] = np.sqrt((extra_df['Latitude'] - la_lat)**2 +
                               (extra_df['Longitude'] - la_lon)**2)
extra_df['DistToSF'] = np.sqrt((extra_df['Latitude'] - sf_lat)**2 +
                               (extra_df['Longitude'] - sf_lon)**2)

extra_df['DistToCity'] = extra_df[['DistToLA', 'DistToSF']].min(axis=1)


city_corr = extra_df.corr()
city_corr['MedHouseVal'].abs().sort_values(ascending=False)


extra_df['DistToCity'].hist(bins=50, figsize=(12, 8))


extra_df['DistToCity'] = np.log1p(extra_df['DistToCity'])
extra_df['DistToCity'].hist(bins=50, figsize=(12, 8))


scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(extra_df),
                         columns=extra_df.columns)

df_scaled.hist(figsize=(16, 16), bins=50)


corr = extra_df.corr()
print(corr["MedHouseVal"].abs().sort_values(ascending=False))


sns.pairplot(extra_df[non_geo])


extra_df.columns


features_to_remove = ['AveRooms', 'AveBedrms',
                      'Latitude', 'Longitude', 'DistToLA', 'DistToSF',
                      'AveBedrmsPerOccup', 'Population', 'HouseAge']

data = extra_df.drop(features_to_remove, axis=1, inplace=False)
data.head()


print(data.columns)


X_features = ['MedInc', 'AveOccup', 'AveBedrmsPerRoom',
              'AveAddRooms', 'EstHouses', 'DistToCity']
y_features = ['MedHouseVal']

X = data[X_features]
y = data[y_features]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


data_train = pd.concat((y_train, X_train), axis=1)
data_test = pd.concat((y_test, X_test), axis=1)


# def normal_linreg(data, formula):
#     with pm.Model() as model:
#         # Normal prior
#         family = pm.glm.families.Normal()
#         # Create model from formula
#         pm.GLM.from_formula(formula, data=data, family=family)
#         return model


# def sample_model(n_samples=1000, n_tune=500, n_cores=2):
#     trace = pm.sample(draws=n_samples, tune=n_tune,
#                       progressbar=True, cores=n_cores)
#     return trace


# formula = "MedHouseVal ~ MedInc + AveOccup + AveBedrmsPerRoom +\
#            AveAddRooms + EstHouses + DistToCity"

# with normal_linreg(data_train, formula):
#     normal_linreg_trace = sample_model(n_samples=5000, n_tune=500,
#                                        n_cores=16)


# pm.save_trace(normal_linreg_trace, directory="traces", overwrite=True)


# pm.traceplot(normal_linreg_trace)


# pm.plot_posterior(normal_linreg_trace)


# pm.forestplot(normal_linreg_trace)


# # calculate mae and rmse for model on X, y
# def score(trace, X, y):
#     # get mean of coefficients
#     all_coeffs = np.asarray([trace[name] for name in trace.varnames])
#     coeff_means = all_coeffs.mean(axis=1)
#     # set intercept and variable coefficients
#     n_coeffs = X.shape[1]
#     coeffs = coeff_means[:n_coeffs+1]
#     # get predictions
#     X = np.column_stack((np.ones((X.shape[0])), X))
#     preds = np.dot(coeffs, X.T)
#     # calculate mae, rmse
#     labels = np.asarray(y).reshape(-1)
#     errors = preds - labels
#     mae = np.mean(abs(errors))
#     rmse = np.sqrt(np.mean(errors**2))
#     return (mae, rmse)


# mae, rmse = score(normal_linreg_trace, X_test, y_test)

# print("Bayesian Linear Regression Mean Results")
# print(f"Mean absolute error     (MAE)  : {mae:.3f}")
# print(f"Root mean squared error (RMSE) : {rmse:.3f}")


# linreg = LinearRegression()
# linreg.fit(X_train, y_train)


# linreg_preds = linreg.predict(X_test)
# linreg_mae = mean_squared_error(y_test, linreg_preds)
# print(linreg_mae)


from bayesian_linear_regressor import BayesianLinearRegression

bayesianreg = BayesianLinearRegression()


bayesianreg.fit(X_train, y_train, n_samples=5000, n_tune=1000, n_cores=16)






