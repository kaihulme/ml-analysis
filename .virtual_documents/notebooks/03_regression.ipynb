import numpy as np
import pandas as pd
import pymc3 as pm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, QuantileTransformer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


housing_data = fetch_california_housing(as_frame=True)

df = housing_data['frame']
print(df.columns)


print(df.dtypes)


latitude = df['Latitude']
longitude = df['Longitude']

fig, ax = plt.subplots(figsize=(12, 8))
plt.title("Geographical Plot of California Housing Data")
plt.xlabel("Latitude")
plt.ylabel("Longitude")
plt.scatter(latitude, longitude, s=10, alpha=0.25)
plt.show()


house_val = df['MedHouseVal']
population = df['Population']

fig, ax = plt.subplots(figsize=(12, 8))
plt.title("California Housing Value and Geographical Location")
plt.xlabel("Latitude")
plt.ylabel("Longitude")
plt.scatter(latitude, longitude, s=population/100, alpha=0.5, c=house_val, cmap='coolwarm')
plt.colorbar().set_label("Median House Value (scale of 0-5)")
plt.show()


df.describe()


non_geo = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',
           'Population', 'AveOccup', 'MedHouseVal']

corr = df[non_geo].corr()
print(corr['MedHouseVal'].abs().sort_values(ascending=False))


fig, ax = plt.subplots(figsize=(12, 8))
ax.set_title("Correlation of Non-Geographical Features", fontsize=16)
mat = ax.matshow(corr)
ax.set_xticks(range(len(non_geo)))
ax.set_yticks(range(len(non_geo)))
ax.set_xticklabels(non_geo, rotation=-90, fontsize=12)
ax.set_yticklabels(non_geo, fontsize=12)
plt.colorbar(mat, ax=ax)
plt.show()


df_nohigh = df.astype(float)
df_nohigh = df_nohigh.drop(df_nohigh[(df_nohigh['MedInc'] > 10) |
                                     (df_nohigh['HouseAge'] > 50) |
                                     (df_nohigh['AveRooms'] > 10) |
                                     (df_nohigh['AveBedrms'] > 2) |
                                     (df_nohigh['Population'] > 6000) |
                                     (df_nohigh['AveOccup'] > 8) |
                                     (df_nohigh['MedHouseVal'] > 4.7)].index)


df_nohigh[non_geo].hist(bins=50, figsize=(12, 8))


df_nohighnormal = df_nohigh.copy()
df_nohighnormal["MedInc"] = np.log1p(df_nohighnormal['MedInc'])
df_nohighnormal["AveRooms"] = np.log1p(df_nohighnormal['AveRooms'])
df_nohighnormal["AveBedrms"] = np.log1p(df_nohighnormal['AveBedrms'])
df_nohighnormal["Population"] = np.log1p(df_nohighnormal['Population'])
df_nohighnormal["AveOccup"] = np.log1p(df_nohighnormal['AveOccup'])
df_nohighnormal["MedHouseVal"] = np.log1p(df_nohighnormal['MedHouseVal'])

df_nohighnormal[non_geo].hist(bins=50, figsize=(12, 8))


df_normal = df.copy()
df_normal["MedInc"] = np.log1p(df_normal['MedInc'])
df_normal["AveRooms"] = np.log1p(df_normal['AveRooms'])
df_normal["AveBedrms"] = np.log1p(df_normal['AveBedrms'])
df_normal["Population"] = np.log1p(df_normal['Population'])
df_normal["AveOccup"] = np.log1p(df_normal['AveOccup'])
df_normal["MedHouseVal"] = np.log1p(df_normal['MedHouseVal'])


df_normal.isnull().sum()


df_cut = df_normal.copy()
df_cut[non_geo].hist(bins=50, figsize=(16, 16))


# df_nohigh = df[non_geo].astype(float)
df_cut = df_cut.drop(df_cut[(df_cut['HouseAge'] > 50) |
                            (df_cut['MedHouseVal'] > 1.75)].index)

df_cut.hist(bins=50, figsize=(12, 8))


print(df_cut.columns)


extra_df = df_cut.copy()

extra_df['AveBedrmsPerRoom'] = extra_df['AveBedrms'] / extra_df['AveRooms']
extra_df['AveBedrmsPerOccup'] = extra_df['AveBedrms'] / extra_df['AveOccup']
extra_df['AveAddRooms'] = extra_df['AveRooms'] - extra_df['AveBedrms']
extra_df['EstHouses'] = extra_df['Population'] / extra_df['AveOccup']

new_features = ['MedHouseVal', 'AveBedrmsPerRoom', 'AveBedrmsPerOccup',
                'AveAddRooms', 'EstHouses']

new_features_corr = extra_df.corr()
new_features_corr['MedHouseVal'].abs().sort_values(ascending=False)

# fig, ax = plt.subplots(figsize=(12, 8))
# ax.set_title("Correlation of Non-Geographical Features", fontsize=16)
# mat = ax.matshow(new_features_corr)
# ax.set_xticks(range(len(new_features)))
# ax.set_yticks(range(len(new_features)))
# ax.set_xticklabels(new_features, rotation=-90, fontsize=12)
# ax.set_yticklabels(new_features, fontsize=12)
# plt.colorbar(mat, ax=ax)
# plt.show()


# LA location as north-westerly peak
la_lat, la_lon = 34.0522, -118.2437
# SF location as south-easterly peak
sf_lat, sf_lon = 37.7749, -122.4194

extra_df['DistToLA'] = np.sqrt((extra_df['Latitude'] - la_lat)**2 +
                               (extra_df['Longitude'] - la_lon)**2)
extra_df['DistToSF'] = np.sqrt((extra_df['Latitude'] - sf_lat)**2 +
                               (extra_df['Longitude'] - sf_lon)**2)

extra_df['DistToCity'] = extra_df[['DistToLA', 'DistToSF']].min(axis=1)


city_corr = extra_df.corr()
city_corr['MedHouseVal'].abs().sort_values(ascending=False)


extra_df['DistToCity'].hist(bins=50, figsize=(12, 8))


town_coords = np.array([[37.4613, -122.1997],
                        [34.0195, -118.4912],
                        [34.0736, -118.4004],
                        [37.4419, -122.1430],
                        [37.3852, -122.1141],
                        [37.9624, -122.5550],
                        [37.3841, -122.2352],
                        [37.3478, -122.1008],
                        [33.6189, -117.9298],
                        [33.6061, -117.8912],
                        [32.7157, -117.1611]])

coords = np.asarray(extra_df[['Latitude', 'Longitude']])

town_dists = np.asarray([np.sqrt((coords[:, 0] - town_coord[0])**2 + 
                                 (coords[:, 1] - town_coord[1])**2) 
                         for town_coord in town_coords])

dist_to_town = np.min(town_dists, axis=0)


extra_df['DistToTown'] = dist_to_town
extra_df['DistToTown'].hist(bins=50, figsize=(12, 8))


city_corr = extra_df.corr()
city_corr['MedHouseVal'].abs().sort_values(ascending=False)


qt = QuantileTransformer(output_distribution="normal")
normal_dist_to_town = qt.fit_transform(dist_to_town.reshape(-1, 1))

extra_df['DistToTown'] = normal_dist_to_town
extra_df['DistToTown'].hist(bins=100, figsize=(12, 8))


scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(extra_df),
                         columns=extra_df.columns)

df_scaled.hist(figsize=(16, 16), bins=50)


qt = QuantileTransformer(output_distribution="normal")
normal_transformed_df = pd.DataFrame(qt.fit_transform(extra_df),
                                     columns=extra_df.columns)

normal_transformed_df.hist(figsize=(16, 16), bins=50)


corr = normal_transformed_df.corr()
print(corr["MedHouseVal"].abs().sort_values(ascending=False))


sns.pairplot(normal_transformed_df[non_geo])


normal_transformed_df.columns


features_to_remove = ['AveRooms', 'AveBedrms', 'Latitude', 'Longitude',
                      'DistToLA', 'DistToSF', 'DistToCity',
                      'AveBedrmsPerOccup', 'Population', 'HouseAge']

data = normal_transformed_df.drop(features_to_remove, axis=1, inplace=False)
data.head()


data.corr()['MedHouseVal'].abs().sort_values(ascending=False)


sns.pairplot(data)


print(data.columns)


X_features = ['MedInc', 'AveOccup', 'AveBedrmsPerRoom',
              'AveAddRooms', 'EstHouses', 'DistToTown']
y_features = ['MedHouseVal']

X = data[X_features]
y = data[y_features]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


data_train = pd.concat((y_train, X_train), axis=1)
data_test = pd.concat((y_test, X_test), axis=1)


import california_data_pipeline as cp
import importlib
importlib.reload(cp)

X_train, X_test, y_train, y_test = cp.load_train_test()


X_train.describe()


y_train.describe()


# def normal_linreg(data, formula):
#     with pm.Model() as model:
#         # Normal prior
#         family = pm.glm.families.Normal()
#         # Create model from formula
#         pm.GLM.from_formula(formula, data=data, family=family)
#         return model


# def sample_model(n_samples=1000, n_tune=500, n_cores=2):
#     trace = pm.sample(draws=n_samples, tune=n_tune,
#                       progressbar=True, cores=n_cores)
#     return trace


# formula = "MedHouseVal ~ MedInc + AveOccup + AveBedrmsPerRoom +\
#            AveAddRooms + EstHouses + DistToCity"

# with normal_linreg(data_train, formula):
#     normal_linreg_trace = sample_model(n_samples=5000, n_tune=500,
#                                        n_cores=16)


# pm.save_trace(normal_linreg_trace, directory="traces", overwrite=True)


# pm.traceplot(normal_linreg_trace)


# pm.plot_posterior(normal_linreg_trace)


# pm.forestplot(normal_linreg_trace)


# # calculate mae and rmse for model on X, y
# def score(trace, X, y):
#     # get mean of coefficients
#     all_coeffs = np.asarray([trace[name] for name in trace.varnames])
#     coeff_means = all_coeffs.mean(axis=1)
#     # set intercept and variable coefficients
#     n_coeffs = X.shape[1]
#     coeffs = coeff_means[:n_coeffs+1]
#     # get predictions
#     X = np.column_stack((np.ones((X.shape[0])), X))
#     preds = np.dot(coeffs, X.T)
#     # calculate mae, rmse
#     labels = np.asarray(y).reshape(-1)
#     errors = preds - labels
#     mae = np.mean(abs(errors))
#     rmse = np.sqrt(np.mean(errors**2))
#     return (mae, rmse)


# mae, rmse = score(normal_linreg_trace, X_test, y_test)

# print("Bayesian Linear Regression Mean Results")
# print(f"Mean absolute error     (MAE)  : {mae:.3f}")
# print(f"Root mean squared error (RMSE) : {rmse:.3f}")


linreg = LinearRegression()
linreg.fit(X_train, y_train)


linreg_preds = linreg.predict(X_test)
linreg_r2 = r2_score(y_test, linreg_preds)
linreg_mse = mean_squared_error(y_test, linreg_preds)
linreg_rmse = mean_squared_error(y_test, linreg_preds, squared=False)
print("Linear regression R2:", linreg_r2)
print("Linear regression MSE:", linreg_mse)
print("Linear regression RMSE", linreg_rmse)


import bayesian_linear_regressor as br
import importlib
importlib.reload(br)

bayesianreg = br.BayesianLinearRegression()


bayesianreg.fit(X_train, y_train, n_samples=5000, n_tune=2000, n_cores=8)


preds = bayesianreg.predict(X_test)


print(bayesianreg.mean_coeffs_)


r2 = bayesianreg.score(X_test, y_test)
print(f"Bayesian linear regression R2: {r2}")
print(f"Bayesian linear regression MSE:  {bayesianreg.mse_}")
print(f"Bayesian linear regression RMSE: {bayesianreg.rmse_}")


model_trace_dict = dict()
for nm in ['k1', 'k2', 'k3', 'k4', 'k5']:
    models_lin[nm].name = 'poly=lin, '+nm
    model_trace_dict.update({models_lin[nm]: traces_lin[nm]})

    models_quad[nm].name = 'poly=quad, '+nm
    model_trace_dict.update({models_quad[nm]: traces_quad[nm]})


dfwaic = pm.compare(model_trace_dict, ic='WAIC')
dfwaic.index = pd.MultiIndex.from_tuples(
    [tuple(k.split(',')) for k,v in dfwaic.iterrows()])

dfwaic
