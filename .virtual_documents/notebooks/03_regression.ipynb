import numpy as np
import pandas as pd
import pymc3 as pm
import theano.tensor as tt
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from scipy.stats import zscore


housing_data = fetch_california_housing(as_frame=True)

df = housing_data['frame']
print(df.columns)


print(df.dtypes)


latitude = df['Latitude']
longitude = df['Longitude']

fig, ax = plt.subplots(figsize=(12, 8))
plt.title("Geographical Plot of California Housing Data")
plt.xlabel("Latitude")
plt.ylabel("Longitude")
plt.scatter(latitude, longitude, s=10, alpha=0.25)
plt.show()


house_val = df['MedHouseVal']
population = df['Population']

fig, ax = plt.subplots(figsize=(12, 8))
plt.title("California Housing Value and Geographical Location")
plt.xlabel("Latitude")
plt.ylabel("Longitude")
plt.scatter(latitude, longitude, s=population/100, alpha=0.5, c=house_val, cmap='coolwarm')
plt.colorbar().set_label("Median House Value (scale of 0-5)")
plt.show()


df.describe()


non_geo = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',
           'Population', 'AveOccup', 'MedHouseVal']

corr = df[non_geo].corr()
print(corr)


fig, ax = plt.subplots(figsize=(12, 8))
ax.set_title("Correlation of Non-Geographical Features", fontsize=16)
mat = ax.matshow(corr)
ax.set_xticks(range(len(non_geo)))
ax.set_yticks(range(len(non_geo)))
ax.set_xticklabels(non_geo, rotation=-90, fontsize=12)
ax.set_yticklabels(non_geo, fontsize=12)
plt.colorbar(mat, ax=ax)
plt.show()


df_nohigh = df[non_geo].astype(float)
df_nohigh = df_nohigh.drop(df_nohigh[(df_nohigh['MedInc'] > 10) |
                                     (df_nohigh['HouseAge'] > 50) |
                                     (df_nohigh['AveRooms'] > 10) |
                                     (df_nohigh['AveBedrms'] > 2) |
                                     (df_nohigh['Population'] > 6000) |
                                     (df_nohigh['AveOccup'] > 8) |
                                     (df_nohigh['MedHouseVal'] > 4.7)].index)


df_nohigh.hist(bins=50, figsize=(16, 16))


df.isnull().sum()


# handle outliers


# handle capped features


print(df.columns)


df['AveBedrmsPerRoom'] = df['AveBedrms'] / df['AveRooms']
df['AveBedrmsPerOccup'] = df['AveBedrms'] / df['AveOccup']
df['AveAddRooms'] = df['AveRooms'] - df['AveBedrms']
df['EstHouses'] = df['Population'] / df['AveOccup']


new_features = ['MedHouseVal', 'AveBedrmsPerRoom', 'AveBedrmsPerOccup', 
                'AveAddRooms', 'EstHouses']

new_features_corr = df[new_features].corr()

fig, ax = plt.subplots(figsize=(12,8))
ax.set_title("Correlation of Non-Geographical Features", fontsize=16)
mat = ax.matshow(new_features_corr)
ax.set_xticks(range(len(new_features)))
ax.set_yticks(range(len(new_features)))
ax.set_xticklabels(new_features, rotation=-90, fontsize=12)
ax.set_yticklabels(new_features, fontsize=12)
plt.colorbar(mat, ax=ax)
plt.show()


corr = df.corr()
print(corr["MedHouseVal"].abs().sort_values(ascending=False))


print(df.columns)


X_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',
              'Population', 'AveOccup', 'Latitude', 'Longitude',
              'AveBedrmsPerRoom', 'AveBedrmsPerOccup',
              'AveAddRooms', 'EstHouses']
y_features = ['MedHouseVal']

data = df
X = df[X_features]
y = df[y_features]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


data_train = pd.concat((y_train, X_train))
data_test = pd.concat((y_test, X_test))


def bayesian_linreg(X, y):
    with pm.Model() as model:
        w = pm.Flat('w', shape=X.shape[1])
        sigma = pm.HalfCauchy('sigma', beta=10.0)
        y_obs = pm.Normal('y', mu=tt.dot(X, w), sd=sigma, observed=y.squeeze())
        return model


def sample_model(model, n_samples=1000, n_cores=2):
    sampler = pm.NUTS()
    trace = pm.sample(n_samples, sampler, progressbar=True, cores=n_cores)
    return trace


samples = 1000
chains = 16
cores = 16

with bayesian_linreg(X_train, y_train):
    bayesian_linear_trace = sample_model(linear_model, samples, cores)


print(corr["MedHouseVal"].abs().sort_values(ascending=False))


X_train_less = X_train.drop(['AveBedrmsPerOccup', 'EstHouses', 'AveBedrms', 'Population', 'AveOccup'], axis=1, inplace=False)
print(X_train_less.columns)


samples = 1000
chains = 16
cores = 16

with bayesian_linreg(X_train, y_train):
    bayesian_linear_trace = sample_model(linear_model, samples, cores)


data_train_less = data_train.drop(['AveBedrmsPerOccup', 'EstHouses', 'AveBedrms', 'Population', 'AveOccup'], axis=1, inplace=False)


formula = "MedHouseVal ~ MedInc + HouseAge + AveRooms + Latitude + Longitude + AveBedrmsPerRoom + AveAddRooms"
print(formula)


# Context for the model
with pm.Model() as normal_model:
    # Normal prior
    family = pm.glm.families.Normal()
    # Create model from formula
    pm.GLM.from_formula(formula, data=data_train_less, family=family)
    # Sample from Markov Chain using NUTS
    normal_trace = pm.sample(draws=2000, chains=16, tune=500, cores=16)
