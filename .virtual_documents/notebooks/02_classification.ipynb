import os
import time
import numpy as np
# import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV
from sklearn.linear_model import Perceptron
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.callbacks import EarlyStopping, TensorBoard
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.activations import relu, selu
from tensorflow.keras.layers import Activation, LeakyReLU, PReLU


X, y = fetch_openml('mnist_784', return_X_y=True)


n_classes = len(np.unique(y))
print(n_classes)


X = np.asarray(X)
y = np.asarray(y)

print(f"X shape: {X.shape}, y shape: {y.shape}")
print(f"Image shape: {X[0].shape}")


print(np.min(X[0]), np.max(X[0]))


print(X.dtype)
print(y.dtype)


X_full = X / 255.0
print(np.min(X_full), np.max(X_full))


y_full = y.astype('int64')
print(y.dtype)


# train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2)

# remove a validation set from the training data
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)


print(X_full.shape[0])
print(X_train.shape[0])
print(X_val.shape[0])
print(X_test.shape[0])


perceptron = Perceptron()
perceptron.fit(X_train, y_train)


perceptron.score(X_val, y_val)


reg_perceptron = Perceptron(alpha=0.0001, tol=0.001,
                            max_iter=1000, early_stopping=True,
                            validation_fraction=0.1, n_iter_no_change=5,
                            random_state=42, verbose=0, n_jobs=-1)

perceptron_params = [{'penalty': ['None', 'l1', 'l2', 'elasticnet']}]

grid_search = GridSearchCV(reg_perceptron, perceptron_params,
                           scoring='accuracy', cv=5,
                           return_train_score=True,
                           verbose=3)

grid_search.fit(X_train, y_train)


grid_search.best_params_


model = Sequential()
model.add(Dense(100, activation="relu", input_shape=[784]))
model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])


model.summary()


history = model.fit(X_train, y_train, epochs=10,
                    validation_data=(X_val, y_val))


def get_tb_dir():
    curr_dir = os.path.join(os.curdir, "tensorboard_logs")
    tb_dir = time.strftime("model_%Y_%m_%d-%H-%M-%S")
    return os.path.join(curr_dir, tb_dir)


tensorboard = TensorBoard(get_tb_dir())


model = Sequential()
model.add(Dense(100, activation="relu", input_shape=[784]))
model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])

history = model.fit(X_train, y_train, epochs=10,
                    validation_data=(X_val, y_val),
                    callbacks=[tensorboard])


# !kill 132185
# %reload_ext tensorboard
# %tensorboard --logdir=./tensorboard_logs --port=6006


model = Sequential()
model.add(Dense(100, activation="relu", input_shape=[784]))
for i in range(30):
    model.add(Dense(100, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])
model.summary()


early_stopping = EarlyStopping(patience=10, restore_best_weights=True)


history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_val, y_val),
                    callbacks=[tensorboard, early_stopping])


# Function to create model, required for KerasClassifier
def create_init_model(init):
    # Sequential model
    model = Sequential()
    # Input layer with activation layer
    model.add(Dense(100, kernel_input_shape=[784]))
    model.add(get_activation(activation))
    # Hidden layers with activation function
    for i in range(21):
        model.add(Dense(50))
        model.add(get_activation(activation))
    # Output layer
    model.add(Dense(10, activation='sigmoid'))
    # Compile model
    model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd',
                  metrics=['accuracy'])
    return model


init_model = KerasClassifier(build_fn=create_init_model, epochs=10)
param_grid = {"init": ['lecun_uniform', 'glorot_normal', 'glorot_uniform',
                       'he_normal', 'he_uniform']}


# Return activation function as layer
def get_activation(activation):
    if (activation == 'relu'):
        return Activation(relu)
    elif (activation == 'selu'):
        return Activation(selu)
    elif (activation == 'leakyrelu'):
        return LeakyReLU()
    elif (activation == 'prelu'):
        return PReLU()
    return False


# Function to create model, required for KerasClassifier
def create_model(activation='relu'):
    # Sequential model
    model = Sequential()
    # Input layer with activation layer
    model.add(Dense(100, input_shape=[784]))
    model.add(get_activation(activation))
    # Hidden layers with activation function
    for i in range(21):
        model.add(Dense(50))
        model.add(get_activation(activation))
    # Output layer
    model.add(Dense(10, activation='sigmoid'))
    # Compile model
    model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd',
                  metrics=['accuracy'])
    return model


np.random.seed(42)
act_model = KerasClassifier(build_fn=create_model, epochs=10)
param_grid = {"activation": ['relu', 'selu', 'leakyrelu', 'prelu']}

# grid search
act_grid = RandomizedSearchCV(act_model, param_grid, n_iter=4, cv=2, verbose=0)
act_grid_results = act_grid.fit(X_train, y_train,
                                validation_data=[X_val, y_val],
                                callbacks=[tensorboard, early_stopping],
                                verbose=0)


act_grid_results.best_params_


model = Sequential()
model.add(BatchNormalization(input_shape=[784]))
model.add(Dense(100, activation="relu"))
for i in range(20):
    model.add(BatchNormalization())
    model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])
model.summary()


history = model.fit(X_train, y_train, epochs=20,
                    validation_data=[X_val, y_val],
                    callbacks=[tensorboard, early_stopping])


model = Sequential()
model.add(BatchNormalization(input_shape=[784]))
model.add(Dense(100, activation="relu"))
for i in range(20):
    model.add(BatchNormalization())
    model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer=SGD(momentum=0.9), metrics=["accuracy"])


history = model.fit(X_train, y_train, epochs=20,
                    validation_data=[X_val, y_val],
                    callbacks=[tensorboard, early_stopping])


def create_lr_model(lr):
    model = Sequential()
    model.add(BatchNormalization(input_shape=[784]))
    model.add(Dense(100, activation="relu"))
    for i in range(20):
        model.add(BatchNormalization())
        model.add(Dense(50, activation="relu"))
    model.add(Dense(10, activation="softmax"))
    model.compile(loss="sparse_categorical_crossentropy",
                  optimizer=SGD(lr=lr, momentum=0.9), metrics=["accuracy"])


np.random.seed(42)
lr_model = KerasClassifier(build_fn=create_model, epochs=10)
param_grid = {"lr": []}

# grid search
lr_grid = RandomizedSearchCV(act_model, param_grid, n_iter=4, cv=2, verbose=0)
lr_grid_results = act_grid.fit(X_train, y_train,
                               validation_data=[X_val, y_val],
                               callbacks=[tensorboard, early_stopping],
                               verbose=0)


drop_model = Sequential()

drop_model.add(BatchNormalization(input_shape=[784]))
drop_model.add(Dense(100, activation="relu"))

for i in range(20):
    drop_model.add(Dense(50, activation="relu"))
    drop_model.add(BatchNormalization())
    drop_model.add(Dropout(rate=0.2))

drop_model.add(Dense(10, activation="softmax"))

drop_model.compile(loss="sparse_categorical_crossentropy",
                   optimizer='sgd', metrics=["accuracy"])


history = drop_model.fit(X_train, y_train, epochs=20,
                         validation_data=[X_val, y_val],
                         callbacks=[tensorboard, early_stopping])
