import os
import time
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import Perceptron
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.callbacks import EarlyStopping, TensorBoard
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier


X, y = fetch_openml('mnist_784', return_X_y=True)


n_classes = len(np.unique(y))
print(n_classes)


X = np.asarray(X)
y = np.asarray(y)

print(f"X shape: {X.shape}, y shape: {y.shape}")
print(f"Image shape: {X[0].shape}")


print(np.min(X[0]), np.max(X[0]))


print(X.dtype)
print(y.dtype)


X_full = X / 255.0
print(np.min(X_full), np.max(X_full))


y_full = y.astype('int64')
print(y.dtype)


# train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2)

# remove a validation set from the training data
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)


print(X_full.shape[0])
print(X_train.shape[0])
print(X_val.shape[0])
print(X_test.shape[0])


perceptron = Perceptron()
perceptron.fit(X_train, y_train)


perceptron.score(X_val, y_val)


reg_perceptron = Perceptron(alpha=0.0001, tol=0.001,
                            max_iter=1000, early_stopping=True,
                            validation_fraction=0.1, n_iter_no_change=5,
                            random_state=42, verbose=0, n_jobs=-1)

perceptron_params = [{'penalty': ['None', 'l1', 'l2', 'elasticnet']}]

grid_search = GridSearchCV(reg_perceptron, perceptron_params,
                           scoring='accuracy', cv=5,
                           return_train_score=True,
                           verbose=3)

grid_search.fit(X_train, y_train)


grid_search.best_params_


model = Sequential()
model.add(Dense(100, activation="relu", input_shape=[784]))
model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])


model.summary()


history = model.fit(X_train, y_train, epochs=10,
                    validation_data=(X_val, y_val))


def get_tb_dir():
    curr_dir = os.path.join(os.curdir, "tensorboard_logs")
    tb_dir = time.strftime("model_%Y_%m_%d-%H-%M-%S")
    return os.path.join(curr_dir, tb_dir)


tensorboard = TensorBoard(get_tb_dir())


model = Sequential()
model.add(Dense(100, activation="relu", input_shape=[784]))
model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])

history = model.fit(X_train, y_train, epochs=10,
                    validation_data=(X_val, y_val),
                    callbacks=[tensorboard])


# !kill 132185
# %reload_ext tensorboard
# %tensorboard --logdir=./tensorboard_logs --port=6006


model = Sequential()
model.add(Dense(100, activation="relu", input_shape=[784]))
for i in range(30):
    model.add(Dense(100, activation="relu"))
model.add(Dense(10, activation="softmax"))

model.compile(loss="sparse_categorical_crossentropy",
              optimizer='sgd', metrics=["accuracy"])
model.summary()


early_stopping = EarlyStopping(patience=10, restore_best_weights=True)

history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_val, y_val),
                    callbacks=[tensorboard, early_stopping])


# Returns keras optimser with lr and momentum
def get_opt(opt, lr, m):
    if (opt == 'sgd'):
        return SGD(lr=lr, momentum=m)
    elif (opt == 'adam'):
        return Adam(lr=lr, momentum=m)
    return False


# Creates model for KerasClassifier
def create_model(init='glorot_uniform', opt='sgd', act='relu',
                 lr=0.01, m=0):
    # sequential model
    model = Sequential()
    # input layer
    model.add(Dense(100, input_shape=[784],
                    kernel_initializer=init, activation=act))
    # hidden layers
    for i in range(10):
        model.add(Dense(100, kernel_initializer=init,
                        activation=act))
    # output layer
    model.add(Dense(10, kernel_initializer=init,
                    activation="softmax"))
    # optimiser
    opt = get_opt(opt, lr, m)
    # compile model
    model.compile(loss="sparse_categorical_crossentropy",
                  optimizer=opt, metrics=["accuracy"])
    return model


np.random.seed(42)
model = KerasClassifier(build_fn=create_model)
