import numpy as np
import pandas as pd
import pymc3 as pm
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor
from california_data_pipeline import load_train_test
from bayesian_linear_regressor import BayesianLinearRegression
import joblib


X_train, X_test, y_train, y_test = load_train_test()


X_train.head()


y_train.head()


tree_reg = DecisionTreeRegressor()
tree_reg.fit(X_train, y_train)


# output R2, MSE and RMSE regressor
def reg_metrics(reg, reg_name, X, y):
    reg_preds = reg.predict(X)
    reg_r2 = r2_score(y, reg_preds)
    reg_mse = mean_squared_error(y, reg_preds)
    reg_rmse = mean_squared_error(y, reg_preds, squared=False)
    print(f"{reg_name} regression R2:   {reg_r2:.4f}")
    print(f"{reg_name} regression MSE:  {reg_mse:.4f}")
    print(f"{reg_name} regression RMSE: {reg_rmse:.4f}")


reg_metrics(tree_reg, "decision tree", X_test, y_test)


forest_reg = RandomForestRegressor(n_estimators=10)
forest_reg.fit(X_train, np.ravel(y_train))


reg_metrics(forest_reg, "random forest", X_test, y_test)


forest_reg = RandomForestRegressor(n_estimators=100)
forest_reg.fit(X_train, np.ravel(y_train))
reg_metrics(forest_reg, "random forest", X_test, y_test)


reg_metrics(forest_reg, "random forest", X_train, y_train)


forest_reg = RandomForestRegressor(n_estimators=5000, max_depth=10, n_jobs=-1)
forest_reg.fit(X_train, np.ravel(y_train))
reg_metrics(forest_reg, "random forest test", X_test, y_test)


reg_metrics(forest_reg, "random forest train", X_train, y_train)


n_estimators = np.arange(100, 1000)
max_features = ['auto', 'sqrt', 'log2']
max_depth = np.arange(3, 20)
min_samples_split = np.arange(1, 100)
min_samples_leaf = np.arange(1, 100)
bootstrap = [True, False]

forest_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}

forest_reg = RandomForestRegressor()

forest_randomcv = RandomizedSearchCV(forest_reg, forest_grid, n_iter=100, cv=2)


forest_randomcv.fit(X_train, np.ravel(y_train))


joblib.dump(forest_randomcv, 'forest_randomcv2.pkl')


forest_randomcv = joblib.load('forest_randomcv2.pkl')


forest_randomcv.best_params_


best_forest = forest_randomcv.best_estimator_


reg_metrics(best_forest, "best random forest regressor", X_test, y_test)


reg_metrics(best_forest, "best random forest test", X_train, y_train)


n_forest_grid = {'n_estimators': [int(x) for x in np.linspace(1, 150, 50)]}

n_forest_gridsearch = GridSearchCV(best_forest,
                                   param_grid=n_forest_grid,
                                   cv=2, return_train_score=True)

n_forest_gridsearch.fit(X_train, np.ravel(y_train))


df = pd.DataFrame()
df['Number of trees'] = n_forest_gridsearch.cv_results_['param_n_estimators']
df['Training time'] = n_forest_gridsearch.cv_results_['mean_fit_time']
df['Train R2 score'] = n_forest_gridsearch.cv_results_['mean_train_score']
df['Test R2 score'] = n_forest_gridsearch.cv_results_['mean_test_score']

fig1_df = df[['Number of trees', 'Train R2 score', 'Test R2 score']]
fig1_df = pd.melt(fig1_df, ['Number of trees'], var_name="",
                  value_name="R2 score")

fig, ax = plt.subplots(figsize=(18, 8))

plt.subplot(121)
fig1 = sns.lineplot(data=fig1_df, x='Number of trees', y='R2 score', hue='')
fig1.set(xlim=[1, 150], ylim=[0.55, 0.8])
fig1.set_title("R2 score for random forest with increasing number of trees")

plt.subplot(122)
fig2 = sns.lineplot(data=df, x="Number of trees", y="Training time")
fig2.set(xlim=[1, 150], ylim=[0, 1])
fig2.set_title("Time to train random forest with increasing number of trees")


depth_grid = {'max_depth': [int(x) for x in np.linspace(1, 30, 20)]}
depth_gridsearch = GridSearchCV(best_forest,
                                param_grid=depth_grid,
                                cv=2, return_train_score=True)
depth_gridsearch.fit(X_train, np.ravel(y_train))


n_features = X_train.shape[1]
features_grid = {'max_features': [int(x) for x in range(1, n_features+1)]}
features_gridsearch = GridSearchCV(best_forest,
                                   param_grid=features_grid,
                                   cv=2, return_train_score=True)
features_gridsearch.fit(X_train, np.ravel(y_train))


df1 = pd.DataFrame()
df1['Max depth'] = depth_gridsearch.cv_results_['param_max_depth']
df1['Train R2 score'] = depth_gridsearch.cv_results_['mean_train_score']
df1['Test R2 score'] = depth_gridsearch.cv_results_['mean_test_score']
fig1_df = df1[['Max depth', 'Train R2 score', 'Test R2 score']]
fig1_df = pd.melt(fig1_df, ['Max depth'], var_name="",
                  value_name="R2 score")

df2 = pd.DataFrame()
df2['Max features'] = features_gridsearch.cv_results_['param_max_features']
df2['Train R2 score'] = features_gridsearch.cv_results_['mean_train_score']
df2['Test R2 score'] = features_gridsearch.cv_results_['mean_test_score']
fig2_df = df2[['Max features', 'Train R2 score', 'Test R2 score']]
fig2_df = pd.melt(fig2_df, ['Max features'], var_name="",
                  value_name="R2 score")


fig, ax = plt.subplots(figsize=(18, 8))

plt.subplot(121)
fig1 = sns.lineplot(data=fig1_df, x='Max depth', y='R2 score', hue='')
fig1.set(xlim=[1, 30], ylim=[0.3, 0.9])
fig1.set_title("Random Forest with Increasing Depth of Decision Trees")

plt.subplot(122)
fig2 = sns.lineplot(data=fig2_df, x="Max features", y="R2 score", hue='')
fig2.set(xlim=[1, 6], ylim=[0.65, 0.8])
fig2.set_title("Random Forest with Increasing Number of Features Condisered")


extra_reg = ExtraTreesRegressor()
extra_reg.fit(X_train, np.ravel(y_train))
reg_metrics(extra_reg, "extra trees test", X_test, y_test)


reg_metrics(extra_reg, "extra trees test", X_train, y_train)


extra_reg = ExtraTreesRegressor(n_estimators=20,
                                min_samples_split=20,
                                min_samples_leaf=10,
                                max_features='sqrt',
                                max_depth=10,
                                bootstrap=True)
extra_reg.fit(X_train, np.ravel(y_train))
reg_metrics(extra_reg, "extra trees train", X_train, y_train)
reg_metrics(extra_reg, "extra trees test ", X_test, y_test)


n_estimators = np.arange(100, 1000)
max_features = ['auto', 'sqrt', 'log2']
max_depth = np.arange(3, 20)
min_samples_split = np.arange(1, 100)
min_samples_leaf = np.arange(1, 100)
bootstrap = [True, False]

extra_grid = {'n_estimators': n_estimators,
              'max_features': max_features,
              'max_depth': max_depth,
              'min_samples_split': min_samples_split,
              'min_samples_leaf': min_samples_leaf,
              'bootstrap': bootstrap}

extra_reg = ExtraTreesRegressor()

extra_randomcv = RandomizedSearchCV(extra_reg, extra_grid, n_iter=100, cv=2)


extra_randomcv.fit(X_train, np.ravel(y_train))


joblib.dump(extra_randomcv, 'extra_randomcv.pkl')


extra_randomcv.best_params_


best_extra = extra_randomcv.best_estimator_
reg_metrics(best_extra, "extra trees train", X_train, y_train)
reg_metrics(best_extra, "extra trees test ", X_test, y_test)


forest_reg = best_forest

estimators = [('forest_reg0', forest_reg),
              ('forest_reg1', forest_reg),
              ('forest_reg2', forest_reg)]

blender = DecisionTreeRegressor(max_depth=10)

stacking_forest = StackingRegressor(estimators=estimators,
                                    final_estimator=blender)


stacking_forest.fit(X_train, np.ravel(y_train))


reg_metrics(stacking_forest, "stacking random forest test", X_test, y_test)


forest_reg = RandomForestRegressor(n_estimators=10, max_depth=10)
estimators = [('forest_reg0', forest_reg),
              ('forest_reg1', forest_reg),
              ('forest_reg2', forest_reg),
              ('forest_reg3', forest_reg),
              ('forest_reg4', forest_reg),
              ('forest_reg5', forest_reg),
              ('forest_reg6', forest_reg),
              ('forest_reg7', forest_reg),
              ('forest_reg8', forest_reg),
              ('forest_reg9', forest_reg)]
blender = DecisionTreeRegressor(max_depth=10)
stacking_forest = StackingRegressor(estimators=estimators,
                                    final_estimator=blender)
stacking_forest.fit(X_train, np.ravel(y_train))
reg_metrics(stacking_forest, "stacking random forest test", X_test, y_test)


import bayesian_linear_regressor as br
import importlib
importlib.reload(br)

X_train, X_test, y_train, y_test = load_train_test()
target = y_train.columns[0]
features = X_train.columns
print(target, features)

bayesian_reg = br.BayesianLinearRegression(target=target,
                                           features=features,
                                           is_frame=False)


# bayesian_regressor = br.BayesianLinearRegression(formula=formula)
forest_reg = RandomForestRegressor(n_estimators=10, max_depth=10)

estimators = [('forest_reg', forest_reg),
              ('bayesian_reg', bayesian_reg)]

blender = DecisionTreeRegressor(max_depth=10)

bayesian_forest_stack = StackingRegressor(estimators=estimators,
                                          final_estimator=blender)


bayesian_forest_stack.fit(X_train, np.ravel(y_train))


bayesian_forest_stack.score(X_test, y_test)


bayesian_regressor = br.BayesianLinearRegression(formula=formula)

forest_estimators = [('forest_reg0', RandomForestRegressor(n_estimators=10,
                                                           max_depth=10)),
                     ('forest_reg1', RandomForestRegressor(n_estimators=10,
                                                           max_depth=10)),
                     ('forest_reg2', RandomForestRegressor(n_estimators=10,
                                                           max_depth=10))]

bayesian_estimators = [('bayesian_reg0', bayesian_regressor),
                       ('bayesian_reg1', bayesian_regressor),
                       ('bayesian_reg2', bayesian_regressor)]

blender = DecisionTreeRegressor()

internal_stack = StackingRegressor(estimators=bayesian_estimators,
                                   final_estimator=blender)

bayesian_forest_stack = StackingRegressor(estimators=forest_estimators,
                                          final_estimator=internal_stack)


bayesian_forest_stack.fit(X_train, y_train)
